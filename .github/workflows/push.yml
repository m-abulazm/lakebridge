name: build

on:
  pull_request:
    types: [opened, synchronize]
  merge_group:
    types: [checks_requested]
  push:
    # Always run on push to main. The build cache can only be reused
    # if it was saved by a run from the repository's default branch.
    # The run result will be identical to that from the merge queue
    # because the commit is identical, yet we need to perform it to
    # seed the build cache.
    branches:
      - main

env:
  HATCH_VERSION: 1.9.1

jobs:
  test-python:
    runs-on:
      group: databrickslabs-protected-runner-group
      labels: linux-ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          cache: 'pip'
          cache-dependency-path: '**/pyproject.toml'
          python-version: '3.10'

      - name: Install hatch
        run: pip install hatch==$HATCH_VERSION

      - name: Run unit tests
        run: hatch run test

      - name: Publish test coverage
        uses: codecov/codecov-action@v5
        with:
          codecov_yml_path: codecov.yml
          token: ${{ secrets.CODECOV_TOKEN }}

  integration-python:
    runs-on:
      group: databrickslabs-protected-runner-group
      labels: linux-ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          cache: 'pip'
          cache-dependency-path: '**/pyproject.toml'
          python-version: '3.10'

      - name: Install hatch
        run: pip install hatch==$HATCH_VERSION

      - name: Setup Spark Remote
        run: |
          chmod +x $GITHUB_WORKSPACE/.github/scripts/setup_spark_remote.sh
          $GITHUB_WORKSPACE/.github/scripts/setup_spark_remote.sh

      - name: Run integration tests
        run: hatch run integration

      - name: Publish test coverage
        uses: codecov/codecov-action@v5
        with:
          codecov_yml_path: codecov.yml
          token: ${{ secrets.CODECOV_TOKEN }}


  fmt-python:
    runs-on:
      group: databrickslabs-protected-runner-group
      labels: linux-ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          cache: 'pip'
          cache-dependency-path: '**/pyproject.toml'
          python-version: 3.10.x

      - name: Install hatch
        run: pip install hatch==$HATCH_VERSION

      - name: Reformat code
        run: make fmt

      - name: Fail on differences
        run: |
          # Exit with status code 1 if there are differences (i.e. unformatted files)
          git diff --exit-code

  python-no-pylint-disable:
    runs-on:
      group: databrickslabs-protected-runner-group
      labels: linux-ubuntu-latest
    if: github.event_name == 'pull_request' && (github.event.action == 'opened' || github.event.action == 'synchronize')
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Verify no lint disabled in the new code
        run: |
          git fetch origin $GITHUB_BASE_REF:$GITHUB_BASE_REF
          git diff --ignore-space-change $GITHUB_BASE_REF...HEAD -- ':(glob,icase)**/*.py '> diff_data.txt
          python tests/unit/no_cheat.py diff_data.txt > cheats.txt
          COUNT=$(cat cheats.txt | wc -c)
          if [ ${COUNT} -gt 1 ]; then
            cat cheats.txt
            exit 1
          fi

  coverage-tests-with-make:
    runs-on:
      group: databrickslabs-protected-runner-group
      labels: linux-ubuntu-latest
    env:
      INPUT_DIR_PARENT: .
      OUTPUT_DIR: ./test-reports
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          cache: 'pip'
          cache-dependency-path: '**/pyproject.toml'
          python-version: 3.10.x

      - name: Install hatch
        run: pip install hatch==$HATCH_VERSION

      - name: Install Databricks CLI
        uses: databricks/setup-cli@main

      - name: Initialize Python virtual environment
        run: make dev

      - name: Create dummy test file
        run: |
          mkdir $INPUT_DIR_PARENT/snowflake
          mkdir $INPUT_DIR_PARENT/tsql
          echo "SELECT * FROM t;" >> $INPUT_DIR_PARENT/snowflake/dummy_test.sql
          echo "SELECT * FROM t;" >> $INPUT_DIR_PARENT/tsql/dummy_test.sql
        shell: bash

      - name: Dry run coverage tests with make
        run: make dialect_coverage_report
        env: # this is a temporary hack
          DATABRICKS_HOST: any
          DATABRICKS_TOKEN: any

      - name: Verify report file
        if: ${{ hashFiles('./test-reports/') == '' }}
        run: |
          echo "No file produced in tests-reports/"
          exit 1

  end-to-end:

    runs-on: ${{ matrix.runner }}
    env: # this is a temporary hack
      DATABRICKS_HOST: any
      DATABRICKS_TOKEN: any

    strategy:
      matrix:
        runner: [larger, windows-server-2022-latest]

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install Python
      uses: actions/setup-python@v5
      with:
        cache: 'pip'
        cache-dependency-path: '**/pyproject.toml'
        python-version: 3.10.x

    - name: Install hatch (Windows)
      if: runner.os == 'Windows'
      run: pip install hatch=="$env:HATCH_VERSION"

    - name: Install hatch (Non-Windows)
      if: runner.os != 'Windows'
      run: pip install hatch==$HATCH_VERSION

    - name: Install Databricks CLI
      uses: databricks/setup-cli@main

    - name: Install JRE 11 (for Morpheus)
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-package: jre
        java-version: 11

    - name: Run install tests
      run: hatch run test-install

    - name: Publish test coverage
      uses: codecov/codecov-action@v5
      with:
        codecov_yml_path: codecov.yml
        token: ${{ secrets.CODECOV_TOKEN }}

